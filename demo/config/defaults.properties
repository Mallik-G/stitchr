#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

## can set here
## baseRegistryFolder=/..demo/registry/
## baseConfigFolder=/..demo/config/
## baseDataFolder=/..demo/data/

## default tmp persistence for session based objects and hive support
## may need to make it dataset specific (based on data source ...
global.logging=true
global.addRunTimeRef=true
global.cloudStorage=false
global.hiveSupport=false
global.defaultTmpContainer=/tmp
global.defaultContainer=/tmp/stitchr
global.overrideDefaultContainer=true
global.defaultFileType=avro
global.defaultWriteMode=append
## EXPERIMENTAL not active yet
global.globalTempDbEnabled=false

## spark (INFO, WARN, ERROR)
spark.logLevel=INFO

app.logLevel=INFO

## catalog parameters
## dc means postgres DC file means file-based registry
dc.persistence=dc
dc.dbengine=postgresql
dc.driver=org.postgresql.Driver
dc.host=localhost
dc.port=5432
dc.db=dc
dc.user=dc
dc.pwd=dc

## EXPERIMENTAL
# #concurrency parameters
## concurrent.threadcount=3
## those are used in testing threaded runs on top of spark.
concurrent.semaphores=2

## used only for testing. data sources are registered in the catalog
jdbc.dbengine=postgresql
jdbc.driver=org.postgresql.Driver
jdbc.host=localhost
jdbc.port=5432
jdbc.db=tpcds
jdbc.fetchsize=10000
jdbc.user=tpcds
jdbc.pwd=tpcds
## set as env variable for testing purposes only
## jdbc.user=
## jdbc.password=

